[{"authors":["admin"],"categories":null,"content":"Alican Bozkurt is a Ph.D. student under supervision of Jennifer Dy, Dana Brooks, and Jan-Willem van de Meent at Northeastern University. His main research interests are machine learning with emphasis on probabilistic programming, deep neural networks, and their applications in biomedical image processing. He is one of the developers of Probabilistic Torch, a library for deep generative models that extends PyTorch, a framework which he also contributes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1556817607,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"http://alicanb.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"Alican Bozkurt is a Ph.D. student under supervision of Jennifer Dy, Dana Brooks, and Jan-Willem van de Meent at Northeastern University. His main research interests are machine learning with emphasis on probabilistic programming, deep neural networks, and their applications in biomedical image processing. He is one of the developers of Probabilistic Torch, a library for deep generative models that extends PyTorch, a framework which he also contributes.","tags":null,"title":"Alican Bozkurt","type":"author"},{"authors":["B. Esmaeili","H. Wu","S. Jain","Alican Bozkurt","N. Siddarth","B. Paige","J. G. Dy","D. H. Brooks","J.W. van de Meent"],"categories":null,"content":"","date":1554350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"bfcb6303a7aa315dbf67676985622571","permalink":"http://alicanb.github.io/publication/aistats-hfvae/","publishdate":"2019-04-04T00:00:00-04:00","relpermalink":"/publication/aistats-hfvae/","section":"publication","summary":"Deep latent-variable models learn representations of high-dimensional data in an unsupervised manner. A number of recent efforts have focused on learning representations that disentangle statistically independent axes of variation by introducing modifications to the standard objective function. These approaches generally assume a simple diagonal Gaussian prior and as a result are not able to reliably disentangle discrete factors of variation. We propose a two-level hierarchical objective to control relative degree of statistical independence between blocks of variables and individual variables within blocks. We derive this objective as a generalization of the evidence lower bound, which allows us to explicitly represent the trade-offs between mutual information between data and representation, KL divergence between representation and prior, and coverage of the support of the empirical data distribution. Experiments on a variety of datasets demonstrate that our objective can not only disentangle discrete variables, but that doing so also improves disentanglement of other variables and, importantly, generalization even to unseen combinations of factors.","tags":[],"title":"Structured Disentagled Representations","type":"publication"},{"authors":["Alican Bozkurt","B. Esmaeili","J. G. Dy","D. H. Brooks","J.W. van de Meent"],"categories":null,"content":"","date":1543899600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"ee9bd90faa18e7c1a08130e4f2627ed9","permalink":"http://alicanb.github.io/publication/cract-vae/","publishdate":"2018-12-04T00:00:00-05:00","relpermalink":"/publication/cract-vae/","section":"publication","summary":"An implicit goal in works on deep generative models is that such models should be able to generate novel examples that were not previously seen in the training data. In this paper, we investigate to what extent this property holds for widely employed variational autoencoder (VAE) architectures. VAEs maximize a lower bound on the log marginal likelihood, which implies that they will in principle overfit the training data when provided with a sufficiently expressive decoder. In the limit of an infinite capacity decoder, the optimal generative model is a uniform mixture over the training data. More generally, an optimal decoder should output a weighted average over the examples in the training data, where the magnitude of the weights is determined by the proximity in the latent space. This leads to the hypothesis that, for a sufficiently high capacity encoder and decoder, the VAE decoder will perform nearest-neighbor matching according to the coordinates in the latent space. To test this hypothesis, we investigate generalization on the MNIST dataset. We consider both generalization to new examples of previously seen classes, and generalization to the classes that were withheld from the training set. In both cases, we find that reconstructions are closely approximated by nearest neighbors for higher-dimensional parameterizations. When generalizing to unseen classes however, lower-dimensional parameterizations offer a clear advantage.","tags":[],"title":"Can VAEs generate novel examples?","type":"publication"},{"authors":["Alican Bozkurt","K. Kose","C. Alessi-Fox","M. Gill","D. H. Brooks","J. G. Dy","M. Rajadhyaksha"],"categories":null,"content":"","date":1534996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"dd309728546f89943c75d9fbffb41cfb","permalink":"http://alicanb.github.io/publication/miccai-munet/","publishdate":"2018-08-23T00:00:00-04:00","relpermalink":"/publication/miccai-munet/","section":"publication","summary":"We describe a new multiresolution 'nested encoder-decoder' convolutional network architecture and use it to annotate morphological patterns in reflectance confocal microscopy (RCM) images of human skin for aiding cancer diagnosis. Skin cancers are the most common types of cancers, melanoma being the deadliest among them. RCM is an effective, non-invasive pre-screening tool for skin cancer diagnosis, with the required cellular resolution. However, images are complex, low-contrast, and highly variable, so that clinicians require months to years of expert-level training to be able to make accurate assessments. In this paper, we address classifying 4 key clinically important structural/textural patterns in RCM images. The occurrence and morphology of these patterns are used by clinicians for diagnosis of melanomas. The large size of RCM images, the large variance of pattern size, the large-scale range over which patterns appear, the class imbalance in collected images, and the lack of fully-labeled images all make this a challenging problem to address, even with automated machine learning tools. We designed a novel nested U-net architecture to cope with these challenges, and a selective loss function to handle partial labeling. Trained and tested on 56 melanoma-suspicious, partially labeled, 12k x 12k pixel images, our network automatically annotated diagnostic patterns with high sensitivity and specificity, providing consistent labels for unlabeled sections of the test images. Providing such annotation will aid clinicians in achieving diagnostic accuracy, and perhaps more important, dramatically facilitate clinical training, thus enabling much more rapid adoption of RCM into widespread clinical use process. In addition, our adaptation of U-net architecture provides an intrinsically multiresolution deep network that may be useful in other challenging biomedical image analysis applications. *First two authors share first authorship.*","tags":[],"title":"A Multiresolution Convolutional Neural Network with Partial Label Training for Annotating Reflectance Confocal Microscopy Images of Skin","type":"publication"},{"authors":["K. Kose","Alican Bozkurt","C. Alessi-Fox","M. Gill","D. H. Brooks","J. G. Dy","M. Rajadhyaksha"],"categories":null,"content":"","date":1522987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"fc2021bcc1ad6693522278d6c2bebb98","permalink":"http://alicanb.github.io/publication/osa-munet/","publishdate":"2018-04-06T00:00:00-04:00","relpermalink":"/publication/osa-munet/","section":"publication","summary":"Morphological tissue patterns in RCM images are critical in diagnosis of melanocytic lesions. We present a multiresolution deep learning framework that can automatically annotate RCM images for these diagnostic patterns with high sensitivity and specificity.","tags":[],"title":"A Multiresolution Deep Learning Framework for Automated Annotation of Reflectance Confocal Microscopy Images","type":"publication"},{"authors":["Alican Bozkurt","T. Gale","K. Kose","C. Alessi-Fox","D. H. Brooks","M. Rajadhyaksha","J. G. Dy"],"categories":null,"content":"","date":1500609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"39568413c55b2c8b899fbca3facfebf5","permalink":"http://alicanb.github.io/publication/cvmi-dej/","publishdate":"2017-07-21T00:00:00-04:00","relpermalink":"/publication/cvmi-dej/","section":"publication","summary":"Reflectance confocal microscopy (RCM) is an effective, non-invasive pre-screening tool for cancer diagnosis. However, acquiring and reading RCM images requires extensive training and experience, and novice clinicians exhibit high variance in diagnostic accuracy. Consequently, there is a compelling need for quantitative tools to standardize image acquisition and analysis. In this study, we use deep recurrent convolutional neural networks to delineate skin strata in stacks of RCM images collected at consecutive depths. To perform diagnostic analysis, clinicians collect RCM images at 4-5 specific layers in the tissue. Our model automates this process by discriminating between RCM images of different layers. Testing our model on an expert labeled dataset of 504 RCM stacks, we achieve 87.97% classification accuracy, and 9-fold reduction in the number of anatomically impossible errors compared to the previous state-of-the-art.","tags":[],"title":"Delineation of Skin Strata in Reflectance Confocal Microscopy Images With Recurrent Convolutional Networks","type":"publication"},{"authors":["Alican Bozkurt","K. Kose","J. Coll-Font","C. Alessi-Fox","D. H. Brooks","J. G. Dy","M. Rajadhyaksha"],"categories":null,"content":"","date":1500609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"d046a88f21790edc298915aabea5fbd5","permalink":"http://alicanb.github.io/publication/ml4h-dej/","publishdate":"2017-07-21T00:00:00-04:00","relpermalink":"/publication/ml4h-dej/","section":"publication","summary":"Reflectance confocal microscopy (RCM) is an effective, non-invasive pre-screening tool for skin cancer diagnosis, but it requires extensive training and experience to assess accurately. There are few quantitative tools available to standardize image acquisition and analysis, and the ones that are available are not interpretable. In this study, we use a recurrent neural network with attention on convolutional network features. We apply it to delineate skin strata in vertically-oriented stacks of transverse RCM image slices in an interpretable manner. We introduce a new attention mechanism called Toeplitz attention, which constrains the attention map to have a Toeplitz structure. Testing our model on an expert labeled dataset of 504 RCM stacks, we achieve 88.17% image-wise classification accuracy, which is the current state-of-art.","tags":[],"title":"Delineation of Skin Strata in Reflectance Confocal Microscopy Images using Recurrent Convolutional Networks with Toeplitz Attention","type":"publication"},{"authors":["K. Kose","Alican Bozkurt","S. Ariafar","C. Alessi-Fox","M. Gill","J. G. Dy","D. H. Brooks","M. Rajadhyaksha"],"categories":null,"content":"","date":1485579600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"56c8336f464525141faf7e52d0ced160","permalink":"http://alicanb.github.io/publication/spie-mosaic/","publishdate":"2017-01-28T00:00:00-05:00","relpermalink":"/publication/spie-mosaic/","section":"publication","summary":"In this study we present a deep learning based classification algorithm for discriminating morphological patterns that appear in RCM mosaics of melanocytic lesions collected at the dermal epidermal junction (DEJ). These patterns are classified into 6 distinct types in the literature: background, meshwork, ring, clod, mixed, and aspecific. Clinicians typically identify these morphological patterns by examination of their textural appearance at 10X magnification. To mimic this process we divided mosaics into smaller regions, which we call tiles, and classify each tile in a deep learning framework. We used previously acquired DEJ mosaics of lesions deemed clinically suspicious, from 20 different patients, which were then labelled according to those 6 types by 2 expert users. We tried three different approaches for classification, all starting with a publicly available convolutional neural network (CNN) trained on natural image, consisting of a series of convolutional layers followed by a series of fully connected layers: (1) We fine-tuned this network using training data from the dataset. (2) Instead, we added an additional fully connected layer before the output layer network and then re-trained only last two layers, (3) We used only the CNN convolutional layers as a feature extractor, encoded the features using a bag of words model, and trained a support vector machine (SVM) classifier. Sensitivity and specificity were generally comparable across the three methods, and in the same ranges as our previous work using SURF features with SVM .  Approach (3) was less computationally intensive to train but more sensitive to unbalanced representation of the 6 classes in the training data. However we expect CNN performance to improve as we add more training data because both the features and the classifier are learned jointly from the data. *First two authors share first authorship.*","tags":[],"title":"Deep learning based classification of morphological patterns in reflectance confocal microscopy to guide noninvasive diagnosis of melanocytic lesions","type":"publication"},{"authors":["Alican Bozkurt","K. Kose","C. Alessi-Fox","J. G. Dy","D. H. Brooks","M. Rajadhyaksha"],"categories":null,"content":"","date":1470974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"ad545db59e2c90926f90f7e61d8c2f9a","permalink":"http://alicanb.github.io/publication/srt-sc/","publishdate":"2016-08-12T00:00:00-04:00","relpermalink":"/publication/srt-sc/","section":"publication","summary":"Measuring the thickness of the stratum corneum (SC) in vivo is often required in pharmacological, dermatological, and cosmetological studies. Reflectance confocal microscopy (RCM) offers a non-invasive imaging-based approach. However, RCM-based measurements currently rely on purely visual analysis of images, which is time-consuming and suffers from inter-user subjectivity. We developed an unsupervised segmentation algorithm that can automatically delineate the SC layer in stacks of RCM images of human skin. We represent the unique textural appearance of SC layer using complex wavelet transform and distinguish it from deeper granular layers of skin using spectral clustering. Moreover, through localized processing in a matrix of small areas (called ‘tiles’), we obtain lateral variation of SC thickness over the entire field of view. On a set of 15 RCM stacks of normal human skin, our method estimated SC thickness with a mean error of 5.4 ± 5.1 μm compared to the ‘ground truth’ segmentation obtained from a clinical expert. Our algorithm provides a non-invasive RCM imaging-based solution which is automated, rapid, objective, and repeatable.","tags":[],"title":"Unsupervised delineation of stratum corneum using reflectance confocal microscopy and spectral clustering","type":"publication"},{"authors":["J.P. Campbell","E. Ataer-Cansizoglu","V. Bolon-Canedo","Alican Bozkurt","D. Erdogmus","J. Kalpathy-Cramer","S.N. Patel","J.D. Reynolds","J. Horowitz","K. Hutcheson","others"],"categories":null,"content":"","date":1464753600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"c0e8686f5a0c2c28f90b6d3c7b63bda5","permalink":"http://alicanb.github.io/publication/opthalmology-rop/","publishdate":"2016-06-01T00:00:00-04:00","relpermalink":"/publication/opthalmology-rop/","section":"publication","summary":"*Importance: Published definitions of plus disease in retinopathy of prematurity (ROP) reference arterial tortuosity and venous dilation within the posterior pole based on a standard published photograph. One possible explanation for limited interexpert reliability for a diagnosis of plus disease is that experts deviate from the published definitions. *Objective: To identify vascular features used by experts for diagnosis of plus disease through quantitative image analysis. *Design, Setting, and Participants: A computer-based image analysis system (Imaging and Informatics in ROP [i-ROP]) was developed using a set of 77 digital fundus images, and the system was designed to classify images compared with a reference standard diagnosis (RSD). System performance was analyzed as a function of the field of view (circular crops with a radius of 1-6 disc diameters) and vessel subtype (arteries only, veins only, or all vessels). Routine ROP screening was conducted from June 29, 2011, to October 14, 2014, in neonatal intensive care units at 8 academic institutions, with a subset of 73 images independently classified by 11 ROP experts for validation. The RSD was compared with the majority diagnosis of experts. *Main Outcomes and Measures: The primary outcome measure was the percentage of accuracy of the i-ROP system classification of plus disease, with the RSD as a function of the field of view and vessel type. Secondary outcome measures included the accuracy of the 11 experts compared with the RSD. *Results: Accuracy of plus disease diagnosis by the i-ROP computer-based system was highest (95%; 95% CI, 94%-95%) when it incorporated vascular tortuosity from both arteries and veins and with the widest field of view (6–disc diameter radius). Accuracy was 90% or less when using only arterial tortuosity and 85% or less using a 2– to 3–disc diameter view similar to the standard published photograph. Diagnostic accuracy of the i-ROP system (95%) was comparable to that of 11 expert physicians (mean 87%, range 79%-99%). *Conclusions and Relevance: Experts in ROP appear to consider findings from beyond the posterior retina when diagnosing plus disease and consider tortuosity of both arteries and veins, in contrast with published definitions. It is feasible for a computer-based image analysis system to perform comparably with ROP experts, using manually segmented images.","tags":[],"title":"Expert diagnosis of plus disease in retinopathy of prematurity from computer-based image analysis","type":"publication"},{"authors":["E. Ataer-Cansizoglu","V. Bolon-Canedo","J.P. Campbell","Alican Bozkurt","D. Erdogmus","J. Kalpathy-Cramer","S.N. Patel","K. Jonas","R.V.P. Chan","S. Ostmo","M.F. Chiang","on behalf of the i-ROP Research Consortium"],"categories":null,"content":"","date":1446350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"a7258cf6342c85a0d9d489ff1699ca9a","permalink":"http://alicanb.github.io/publication/tvst-rop/","publishdate":"2015-11-01T00:00:00-04:00","relpermalink":"/publication/tvst-rop/","section":"publication","summary":"*Purpose: We developed and evaluated the performance of a novel computer-based image analysis system for grading plus disease in retinopathy of prematurity (ROP), and identified the image features, shapes, and sizes that best correlate with expert diagnosis. *Methods: A dataset of 77 wide-angle retinal images from infants screened for ROP was collected. A reference standard diagnosis was determined for each image by combining image grading from 3 experts with the clinical diagnosis from ophthalmoscopic examination. Manually segmented images were cropped into a range of shapes and sizes, and a computer algorithm was developed to extract tortuosity and dilation features from arteries and veins. Each feature was fed into our system to identify the set of characteristics that yielded the highest-performing system compared to the reference standard, which we refer to as the “i-ROP” system. *Results: Among the tested crop shapes, sizes, and measured features, point-based measurements of arterial and venous tortuosity (combined), and a large circular cropped image (with radius 6 times the disc diameter), provided the highest diagnostic accuracy. The i-ROP system achieved 95% accuracy for classifying preplus and plus disease compared to the reference standard. This was comparable to the performance of the 3 individual experts (96%, 94%, 92%), and significantly higher than the mean performance of 31 nonexperts (81%). *Conclusions: This comprehensive analysis of computer-based plus disease suggests that it may be feasible to develop a fully-automated system based on wide-angle retinal images that performs comparably to expert graders at three-level plus disease discrimination. Translational Relevance: Computer-based image analysis, using objective and quantitative retinal vascular features, has potential to complement clinical ROP diagnosis by ophthalmologists.","tags":["retinopathy of prematurity"],"title":"Computer-Based Image Analysis for Plus Disease Diagnosis in Retinopathy of Prematurity: Performance of the “i-ROP” System and Image Features Associated With Expert Diagnosis","type":"publication"},{"authors":["Alican Bozkurt","P. Duygulu","A.E. Cetin"],"categories":null,"content":"","date":1437624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"69c11c9eabb241abf55f9c4b2e81abe2","permalink":"http://alicanb.github.io/publication/sivp-fonts/","publishdate":"2015-07-23T00:00:00-04:00","relpermalink":"/publication/sivp-fonts/","section":"publication","summary":"Recognizing fonts has become an important task in document analysis, due to the increasing number of available digital documents in different fonts and emphases. A generic font recognition system independent of language, script and content is desirable for processing various types of documents. At the same time, categorizing calligraphy styles in handwritten manuscripts is important for paleographic analysis, but has not been studied sufficiently in the literature. We address the font recognition problem as analysis and categorization of textures. We extract features using complex wavelet transform and use support vector machines for classification. Extensive experimental evaluations on different datasets in four languages and comparisons with state-of-the-art studies show that our proposed method achieves higher recognition accuracy while being computationally simpler. Furthermore, on a new dataset generated from Ottoman manuscripts, we show that the proposed method can also be used for categorizing Ottoman calligraphy with high accuracy.","tags":[],"title":"Classifying fonts and calligraphy styles using complex wavelet transform","type":"publication"},{"authors":["Alican Bozkurt","A. Suhre","A.E. Cetin"],"categories":null,"content":"","date":1407384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"18f962f94d8bc563ecec330ab6e0d5e6","permalink":"http://alicanb.github.io/publication/sivp-fl/","publishdate":"2014-08-07T00:00:00-04:00","relpermalink":"/publication/sivp-fl/","section":"publication","summary":"Follicular lymphoma (FL) is a group of malignancies of lymphocyte origin that arise from lymph nodes, spleen, and bone marrow in the lymphatic system. It is the second most common non-Hodgkins lymphoma. Characteristic of FL is the presence of follicle center B cells consisting of centrocytes and centroblasts. Typically, FL images are graded by an expert manually counting the centroblasts in an image. This is time consuming. In this paper, we present a novel multi-scale directional filtering scheme and utilize it to classify FL images into different grades. Instead of counting the centroblasts individually, we classify the texture formed by centroblasts. We apply our multi-scale directional filtering scheme in two scales and along eight orientations, and use the mean and the standard deviation of each filter output as feature parameters. For classification, we use support vector machines with the radial basis function kernel. We map the features into two dimensions using linear discriminant analysis prior to classification. Experimental results are presented.","tags":[],"title":"Multi-scale directional-filtering-based method for follicular lymphoma grading","type":"publication"},{"authors":["M. Tofighi","Alican Bozkurt","K. Kose","A.E. Cetin"],"categories":null,"content":"","date":1402545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"6adc4693e21ecfb8d44bf828c34388fc","permalink":"http://alicanb.github.io/publication/siu-pocs-deconvolution/","publishdate":"2014-06-12T00:00:00-04:00","relpermalink":"/publication/siu-pocs-deconvolution/","section":"publication","summary":"A new deconvolution algorithm based on making orthogonal projections onto the epigraph set of a convex cost function is presented. In this algorithm, the dimension of the minimization problem is lifted by one and sets corresponding to the cost function and observations are defined. If the utilized cost function is convex in R^N, the corresponding epigraph set is also convex in R^(N+1). The deconvolution algorithm starts with an arbitrary initial estimate in R^(N+1). At each iteration cycle of the algorithm, first deconvolution projections are performed onto the hyperplanes representing observations, then an orthogonal projection is performed onto epigraph of the cost function. The method provides globally optimal solutions for total variation, l1, l2, and entropic cost functions.","tags":[],"title":"Deconvolution using projections onto the epigraph set of a convex cost function","type":"publication"},{"authors":["A.E. Cetin","Alican Bozkurt","O. Gunay","Y.H. Habiboglu","K. Kose","I. Onaran","M. Tofighi","R.A. Sevimli"],"categories":null,"content":"","date":1392267600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555566752,"objectID":"bba254ba1eb9795b9516fa305a3b5dcb","permalink":"http://alicanb.github.io/publication/globalsip-pocs/","publishdate":"2014-02-13T00:00:00-05:00","relpermalink":"/publication/globalsip-pocs/","section":"publication","summary":"A new optimization technique based on the projections onto convex space (POCS) framework for solving convex and some non-convex optimization problems are presented. The dimension of the minimization problem is lifted by one and sets corresponding to the cost function are defined. If the cost function is a convex function in RN the corresponding set which is the epigraph of the cost function is also a convex set in R^N+1. The iterative optimization approach starts with an arbitrary initial estimate in RN+1 and an orthogonal projection is performed onto one of the sets in a sequential manner at each step of the optimization problem. The method provides globally optimal solutions in total-variation, filtered variation, l_1, and entropic cost functions. It is also experimentally observed that cost functions based on l_p; p ","tags":[],"title":"Projections onto convex sets (POCS) based optimization by lifting","type":"publication"}]